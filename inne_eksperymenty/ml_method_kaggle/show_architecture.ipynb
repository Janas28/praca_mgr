{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.16.1\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from packaging import version\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "    \"This notebook requires TensorFlow 2.0 or above.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.16.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorboard\n",
    "tensorboard.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import LSTM,GRU,Dense,MaxPooling1D,Dropout\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import add,Conv1D\n",
    "from tensorflow.keras.layers import Input,BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\u144572\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(Conv1D(2048, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(52, 1)))\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv1D(1024, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(512, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(LSTM(128))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "optimiser = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "model.compile(optimizer=optimiser, loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    cycles       filename\n",
      "0       10          10(1)\n",
      "1       10          10(2)\n",
      "2       10          10(3)\n",
      "3       10             10\n",
      "4       11   11 normalnie\n",
      "..     ...            ...\n",
      "59       9  ustami_idąc_9\n",
      "60       6            Ła6\n",
      "61       6         Łagie6\n",
      "62       4          €-€-4\n",
      "63       7           €€_7\n",
      "\n",
      "[64 rows x 2 columns]\n",
      "Epoch 1/2\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - loss: 76.2626 - mae: 8.0034 - val_loss: 64.9277 - val_mae: 7.7845\n",
      "Epoch 2/2\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 439ms/step - loss: 63.0686 - mae: 7.3536 - val_loss: 64.0902 - val_mae: 7.7297\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Lista plików (zakładając, że masz już listę plików, np. z os.listdir)\n",
    "file_list = os.listdir('own_data')  # Zastąp 'ścieżka_do_twojego_folderu' odpowiednią ścieżką\n",
    "\n",
    "# Inicjalizacja listy do przechowywania danych\n",
    "data = []\n",
    "\n",
    "# Iteracja po liście plików\n",
    "for filename in file_list:\n",
    "    # Wydobywanie liczby całkowitej z nazwy pliku przy użyciu wyrażenia regularnego\n",
    "    match = re.search(r'\\d+', filename)  # Zakładając, że liczba całkowita składa się z co najmniej jednej cyfry\n",
    "    if match:\n",
    "        integer = int(match.group())\n",
    "        data.append({'cycles': integer, 'filename': filename[:-4]})\n",
    "\n",
    "# Konwersja listy do DataFrame\n",
    "df = pd.DataFrame(data, columns=['cycles', 'filename'])\n",
    "# print(type(df[\"cycles\"][0]))\n",
    "df\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Parametry zduplikowania\n",
    "duplication_factor = 1  # Ilość zduplikowania danych\n",
    "\n",
    "# Wczytanie danych z CSV\n",
    "audio_data = \"own_data/\"\n",
    "# df = pd.read_csv('cycles_count_own_data.csv', names=['Start', 'filename'], header=0)\n",
    "print(df)\n",
    "\n",
    "def mfcc_feature_extraction_rr(dir_):\n",
    "    X_ = []\n",
    "    y_ = []\n",
    "    data = df\n",
    "    features = 50\n",
    "    for soundDir in os.listdir(dir_):\n",
    "        if soundDir[-3:] == 'wav':               \n",
    "            data_x, sampling_rate = librosa.load(dir_ + soundDir, res_type='kaiser_fast')\n",
    "            mfccs = np.mean(librosa.feature.mfcc(y=data_x, sr=sampling_rate, n_mfcc=features).T, axis=0)\n",
    "            # Dodajemy cechy i etykiety\n",
    "            X_.append(mfccs)\n",
    "            y_.append(list(data[data['filename'] == (soundDir[:-4])]['cycles'])[0])\n",
    "    \n",
    "    # Zduplikowanie danych\n",
    "    X_data = np.tile(np.array(X_), (duplication_factor, 1))\n",
    "    y_data = np.tile(np.array(y_), duplication_factor)\n",
    "    \n",
    "    return X_data, y_data\n",
    "\n",
    "# Wywołanie funkcji ekstrakcji cech\n",
    "res_data, res_y = mfcc_feature_extraction_rr(audio_data)\n",
    "\n",
    "\n",
    "# # Podział danych na zbiory treningowe, walidacyjne i testowe\n",
    "x_train, x_val, y_train, y_val = train_test_split(res_data, res_y, test_size=0.2, random_state=10)\n",
    "\n",
    "# # Wyświetlenie rozmiarów zbiorów danych\n",
    "# print(x_train.shape, x_val.shape)\n",
    "# print(y_train.shape, y_val.shape)\n",
    "\n",
    "x_train_lstm = np.expand_dims(x_train,axis=2)\n",
    "x_val_lstm = np.expand_dims(x_val,axis=2)\n",
    "\n",
    "# # Podział danych na zbiory treningowe, walidacyjne i testowe\n",
    "# x_train, x_val, y_train, y_val = train_test_split(res_data, res_y, test_size=0.175, random_state=10)\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.175, random_state=10)\n",
    "\n",
    "# # Wyświetlenie rozmiarów zbiorów danych\n",
    "# print(x_train.shape, x_val.shape, x_test.shape)\n",
    "# print(y_train.shape, y_val.shape, y_test.shape)\n",
    "\n",
    "# x_train_lstm = np.expand_dims(x_train,axis=2)\n",
    "# x_val_lstm = np.expand_dims(x_val,axis=2)\n",
    "# x_test_lstm = np.expand_dims(x_test,axis=2)\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the Keras TensorBoard callback.\n",
    "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "history = model.fit(\n",
    "    x_train_lstm, y_train, batch_size=16, epochs=2, validation_data=(x_val_lstm, y_val),\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 25152), started 0:02:49 ago. (Use '!kill 25152' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3cad88344268a6db\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3cad88344268a6db\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
